<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Yen-Cheng Liu</title>

  <!-- Bootstrap core CSS -->
  <link href="assets/css/bootstrap.css" rel="stylesheet">


  <!-- Custom styles for this template -->
  <link href="assets/css/main.css" rel="stylesheet">

  <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
  <script src="assets/js/hover.zoom.js"></script>
  <script src="assets/js/hover.zoom.conf.js"></script>

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
</head>

<body>

  <!-- Static navbar -->
  <div class=" navbar">
    <div class="container">
      <div class="navbar-brand">
        <h6>Yen-Cheng Liu</h6>
      </div>
    </div>
  </div>

  <!-- +++++ Welcome Section +++++ -->
  <div id="white">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 col-lg-offset-1 centered">
          <img src="assets/img/user2.png" alt="Yen-Cheng" height="150" width="150">
          <h1>Yen-Cheng Liu</h1>
          <p>
            I am a <b>PhD student at Georgia Tech</b> and work with Prof. <a
              href="https://www.cc.gatech.edu/~zk15/" target="_blank">Zsolt Kira</a>. Previously, I am fortunate to work with Prof. <a
              href="http://vllab.ee.ntu.edu.tw/ycwang.html" target="_blank">Yu-Chiang Frank Wang</a> at NTU. 
            </p>
            <p>
            My research interests are in the areas of computer vision and machine learning.
            Specifically, I was/am working on improving the <b>efficiency</b> (label-efficiency, data-efficiency, parameter-efficiency, and communication-efficiency) of <b>scene understanding </b> (object detection, depth estimation, segmentation, etc.).
              <p> <b>I am currently looking for a full-time position starting from Fall 2023 :) </b></p>
    
    
          [<a href="assets/file/cv.pdf" target="_blank">CV</a>] [<a
            href="https://scholar.google.com/citations?user=yeAeAhsAAAAJ&hl=en" target="_blank">Google Scholar<a>] <br>
              <img class="rounded" src="assets/img/email_icon.png" align="" height="15" width="15" /> ycliu [AT] gatech
              [DOT] edu

        </div><!-- /col-lg-8 -->
      </div><!-- /row -->

    </div> <!-- /container -->
  </div><!-- /ww -->

  <!-- +++++ Projects Section +++++ -->
  <div id="white">
    <div class="container">

      <h2>Publications</h2>

      <!-- ECCV ' 22 OSSOD -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="assets/file/ECCV22_OSSOD.pdf" target="_blank"><img class="img-responsive"
              src="assets/img/project/eccv2022.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Open-set Semi-supervised Object Detection</h4>
          <h7>European Conference on Computer Vision 2022 <b>
              <font color="#1387C4">(ECCV 2022)</font>
            </b></h7><br>
          <h7> <b>Yen-Cheng Liu</b>, Chih-Yao Ma, Xiaoliang Dai, Junjiao Tian, Peter Vajda, Zijian He, Zsolt Kira
          </h7> <br>
          [<a href="assets/file/ECCV22_OSSOD.pdf" target="_blank">Paper</a>] [<a href="projects/ossod.html" target="_blank">Project Page</a>] [<a href="" target="_blank">Code</a> (Coming Soon)]<br>

        </div>
      </div><!-- /row -->

      <center>
        <hr width="100%">
      </center>



      <!-- CVPR ' 22 UTv2 -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.pdf" target="_blank"><img class="img-responsive"
              src="assets/img/project/cvpr2022.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free and Anchor-based Detectors</h4>
          <h7>IEEE / CVF Computer Vision and Pattern Recognition Conference <b>
              <font color="#1387C4">(CVPR 2022)</font>
            </b></h7><br>
          <h7> <b>Yen-Cheng Liu</b>, Chih-Yao Ma, Zsolt Kira
          </h7> <br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.pdf" target="_blank">Paper</a>] [<a href="projects/unbiasedteacher2.html" target="_blank">Project Page</a>] [<a href="https://github.com/facebookresearch/unbiased-teacher-v2" target="_blank">Code</a>]<br>

        </div>
      </div><!-- /row -->

      <center>
        <hr width="100%">
      </center>


      <!-- ICLR ' 21 UT -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="https://openreview.net/forum?id=MJIve1zgR_" target="_blank"><img class="img-responsive"
              src="assets/img/project/iclr2021.gif" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Unbiased Teacher for Semi-Supervised Object Detection</h4>
          <h7>International Conference on Learning Representations <b>
              <font color="#1387C4">(ICLR 2021)</font>
            </b></h7><br>
          <h7> <b>Yen-Cheng Liu</b>, Chih-Yao Ma, Zijian He, Chia-Wen Kuo, Kan Chen, Peizhao Zhang, Bichen Wu, Zsolt
            Kira, Peter Vajda
          </h7> <br>
          [<a href="https://openreview.net/forum?id=MJIve1zgR_" target="_blank">Paper</a>] [<a href="projects/unbiasedteacher.html" target="_blank">Project Page</a>] [<a href="https://github.com/facebookresearch/unbiased-teacher" target="_blank">Code</a>]<br>

        </div>
      </div><!-- /row -->

      <center>
        <hr width="100%">
      </center>

      <!-- NIPS ' 20 imbalance -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green"
            href="http://papers.nips.cc/paper/7525-a-unified-feature-disentangler-for-multi-domain-image-translation-and-manipulation"
            target="_blank"><img class="img-responsive" src="assets/img/project/nips2020.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Posterior Re-calibration for Imbalanced Datasets</h4>
          <h7>Advances in Neural Information Processing Systems <b>
              <font color="#1387C4">(NeurIPS 2020)</font>
            </b></h7><br>Junjiao Tian, <h7><b>Yen-Cheng Liu</b>, Nathaniel Glaser, Yen-Chang Hsu, Zsolt Kira</h7> <br>
          [<a href="https://arxiv.org/abs/2010.11820" target="_blank">Paper</a>] [<a
            href="https://github.com/GT-RIPL/UNO-IC" target="_blank">Code</a>] <br>

        </div>
      </div><!-- /row -->

      <center>
        <hr width="100%">
      </center>

      <!-- CVPR ' 20 when -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="" target="_blank"><img class="img-responsive" src="assets/img/project/cvpr20.png"
              alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>When2com: Multi-Agent Perception via Communication Graph Grouping</h4>
          <h7>IEEE Conference on Computer Vision and Pattern Recognition <b>
              <font color="#1387C4">(CVPR 2020)</font>
            </b></h7><br>
          <h7> <b>Yen-Cheng Liu</b>, Junjiao Tian*, Nathaniel Glaser*, Zsolt Kira </h7> (* indicates equal contribution)
          <br>
          [<a href="projects/multi-agent-perception.html" target="_blank">Project Page</a>] <br>

        </div>
      </div><!-- /row -->
      <center>
        <hr width="100%">
      </center>

      <!-- ICRA ' 20 who -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="" target="_blank"><img class="img-responsive"
              src="assets/img/project/icra20who.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Who2com: Collaborative Perception via Learnable Handshake Communication</h4>
          <h7>International Conference on Robotics and Automation <b>
              <font color="#1387C4">(ICRA 2020)</font>
            </b></h7><br>
          <h7> <b>Yen-Cheng Liu</b>, Junjiao Tian, Chih-Yao Ma, Nathaniel Glaser, Chia-Wen Kuo, Zsolt Kira </h7> <br>
          [<a href="https://arxiv.org/abs/2003.09575" target="_blank">Paper</a>] [<a
            href="projects/multi-agent-perception.html" target="_blank">Project Page</a>]
          <br>
        </div>
      </div><!-- /row -->
      <center>
        <hr width="100%">
      </center>

      <!-- ICRA ' 20 uncertainty -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="" target="_blank"><img class="img-responsive"
              src="assets/img/project/icra20uno.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>UNO: Uncertainty-aware Noisy-Or Multimodal Fusion for Unanticipated Input Degradation</h4>
          <h7>International Conference on Robotics and Automation <b>
              <font color="#1387C4">(ICRA 2020) </font>
            </b></h7><br>
          <h7>Junjiao Tian, Wesley Cheung, Nathan Glaser, <b>Yen-Cheng Liu</b>, Zsolt Kira </h7> <br>
          [<a href="https://arxiv.org/abs/1911.05611" target="_blank">Paper</a>] <br>

        </div>
      </div><!-- /row -->
      <center>
        <hr width="100%">
      </center>

      <!-- CVPR ' 19 Scene -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="" target="_blank"><img class="img-responsive" src="assets/img/project/cvpr19.gif"
              alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Towards Scene Understanding: Unsupervised Monocular Depth Estimation with Semantic-aware Representation
          </h4>
          <h7>IEEE Conference on Computer Vision and Pattern Recognition <b>
              <font color="#1387C4">(CVPR 2019; Oral) </font>
            </b></h7><br>
          <h7>Po-Yi Chen*, Alexander H. Liu*, <b>Yen-Cheng Liu</b>, Yu-Chiang Frank Wang </h7> (* indicates equal
          contribution) <br>
          [<a
            href="http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.html"
            target="_blank">Paper</a>] <br>

        </div>
      </div><!-- /row -->
      <center>
        <hr width="100%">
      </center>

      <!-- ICLR ' 19 Closer -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="https://arxiv.org/abs/1705.01314" target="_blank"><img class="img-responsive"
              src="assets/img/project/iclr19.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>A Closer Look at Few-shot Classification</h4>
          <h7>International Conference on Learning Representations <b>
              <font color="#1387C4">(ICLR 2019)</font>
            </b></h7><br>
          <h7>Wei-Yu Chen, <b>Yen-Cheng Liu</b>, Zsolt Kira, Yu-Chiang Frank Wang, Jia-Bin Huang</h7> <br>
          [<a href="https://sites.google.com/view/a-closer-look-at-few-shot" target="_blank">Project Page</a>][<a
            href="https://openreview.net/forum?id=HkxLXnAcFQ" target="_blank">Paper</a>] [<a
            href="https://github.com/wyharveychen/CloserLookFewShot" target="_blank">Code</a>]<br>

        </div>
      </div><!-- /row -->

      <center>
        <hr width="100%">
      </center>

      <!-- NIPS ' 18 detach -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green"
            href="http://papers.nips.cc/paper/7525-a-unified-feature-disentangler-for-multi-domain-image-translation-and-manipulation"
            target="_blank"><img class="img-responsive" src="assets/img/project/nips18.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>A Unified Feature Disentangler for Multi-Domain Image Translation and Manipulation</h4>
          <h7>Advances in Neural Information Processing Systems <b>
              <font color="#1387C4">(NeurIPS 2018)</font>
            </b></h7><br>Alexendar Liu,
          <h7><b>Yen-Cheng Liu</b>, <a href="https://yuyingyeh.github.io/" target="_blank">Yu-Ying Yeh</a>, Yu-Chiang
            Frank Wang</h7> <br>
          [<a href="https://arxiv.org/abs/1809.01361" target="_blank">Paper</a>] [<a
            href="https://github.com/XenderLiu/UFDN" target="_blank">Code</a>] <br>

        </div>
      </div><!-- /row -->

      <center>
        <hr width="100%">
      </center>


      <!-- CVPR ' 18 detach -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="https://arxiv.org/abs/1705.01314" target="_blank"><img class="img-responsive"
              src="assets/img/project/cvpr18.gif" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Detach and Adapt: Learning Cross-Domain Disentangled Deep Representation</h4>
          <h7>IEEE Conference on Computer Vision and Pattern Recognition <b>
              <font color="#1387C4">(CVPR 2018; Spotlight) </font>
            </b></h7><br>
          <h7><b>Yen-Cheng Liu</b>, <a href="https://yuyingyeh.github.io/" target="_blank">Yu-Ying Yeh</a>, Tzu-Chien
            Fu, Sheng-De Wang, Wei-Chen Chiu, Yu-Chiang Frank Wang</h7> <br>
          [<a href="https://arxiv.org/abs/1705.01314" target="_blank">Paper</a>] [<a
            href="https://github.com/ycliu93/CDRD" target="_blank">Code</a>]<br>

        </div>
      </div><!-- /row -->
      <center>
        <hr width="100%">
      </center>




      <!-- NIPSWÍ 18 CL -->
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="https://arxiv.org/abs/1804.09347" target="_blank"><img class="img-responsive"
              src="assets/img/project/nipsw18.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Re-evaluating Continual Learning Scenarios: A Categorization and Case for Strong Baselines </h4>
          <h7>Advances in Neural Information Processing Systems Workshops <b>(NeurIPS Workshops 2018)</b></h7><br>
          <h7>Yen-Chang Hsu, <b>Yen-Cheng Liu</b>, Anita Ramasamy, Zsolt Kira</h7> <br>
          [<a href="https://arxiv.org/abs/1810.12488" target="_blank">Paper</a>] [<a
            href="https://github.com/GT-RIPL/Continual-Learning-Benchmark" target="_blank">Code</a>] <br>
        </div>
      </div><!-- /row -->


      <center>
        <hr width="100%">
      </center>

      <!-- CVPRW 18 Reid
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green" href="https://arxiv.org/abs/1804.09347" target="_blank"><img class="img-responsive"
              src="assets/img/project/cvprw_reid.jpg" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Adaptation and Re-Identification Network: An Unsupervised Deep Transfer Learning Approach to Person
            Re-Identification </h4>
          <h7>IEEE Conference on Computer Vision and Pattern Recognition Workshops <b>(CVPR'18 Workshops)</b></h7><br>
          <h7><a href="https://yujheli.github.io/" target="_blank">Yu-Jhe Li</a>, Fu-En Yang, <b>Yen-Cheng Liu</b>, <a
              href="https://yuyingyeh.github.io/" target="_blank">Yu-Ying Yeh</a>, Xiaofei Du, Yu-Chiang Frank Wang</h7>
          <br>
          [<a href="https://arxiv.org/abs/1804.09347" target="_blank">arXiv</a>] <br>
        </div>
      </div> /row -->

      <!-- CVPRW 18 Deep Global 
      <div class="row vertical-align">
        <div class="col-lg-3">
          <a class="zoom green"
            href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Kuo_Deep_Aggregation_Net_CVPR_2018_paper.pdf"
            target="_blank">
            <img class="img-responsive" src="assets/img/project/cvprw18_deepglobal.png" alt="" /></a>
        </div>
        <div class="col-lg-8 ">
          <h4>Deep Aggregation Net for Land Cover Classification</h4>
          <h7>IEEE Conference on Computer Vision and Pattern Recognition Workshops <b>(CVPR'18 Workshops)</b></h7><br>
          <h7>Tzu-Sheng Kuo, Keng-Sen Tseng, Jia-Wei Yan, <b>Yen-Cheng Liu</b>, Yu-Chiang Frank Wang</h7> <br>
        </div>
      </div> /row -->


    </div> <!-- /container -->
  </div><!-- /white -->


  <!-- +++++ Projects Section +++++ -->
  <div id="grey">
    <div class="container">
      <h2>Side Projects</h2>


      <!-- +++++ Robotics +++++ -->
      <div class="row vertical-align">
        <div class="col-lg-6  ">
          <h4>Jenga Builder</h4>
          <h7>Collaborator: Kilian Contamain, Edwinn Gamborino, Da-Wei Liu</h7> <br>
          <div style="text-align: justify">
            <small>The proposed system aim at rebuilding a Jenga® tower from a randomly positioned and relatively large
              set of pieces in a surface using only one RGB camera and a 6-DOF robotic manipulator </small>
          </div>
        </div>

        <div class="col-lg-6 ">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/lEt5kOAXQ2A?rel=0&amp;showinfo=0"
            frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
        </div>
      </div><!-- /row -->

      <br>
      <center>
        <hr width="100%">
      </center><br>


    </div> <!-- /container -->
  </div><!-- /white -->




  <!-- +++++ Education Section +++++ -->
  <div id="grey">
    <div class="container">
      <div class="row centered">
        <div class="col-lg-2">
        </div>

        <!-- <div class="col-lg-2">
          <img class="rounded" src="assets/img/school/fb.png" alt="" align="" height="150" width="150" />
          <p>Research Intern<br>Facebook Research<br>May '20 - Aug '20</p>
        </div> -->


        <div class="col-lg-2">
          <img class="rounded" src="assets/img/school/gt.png" alt="" align="" height="150" width="150" />
          <p>Ph.D. Student in ML<br>Georgia Tech<br>Aug '18 - Present</p>
        </div>



        <div class="col-lg-2">
          <img class="rounded" src="assets/img/school/ntu.png" alt="" align="" height="150" width="150" />
          <p>M.S. in EE<br>NTU<br>Sep '15 - June '17</p>
        </div>


        <!-- <div class="col-lg-2">
          <img class="rounded" src="assets/img/school/as.png" alt="" align="" height="150" width="150" />
          <p>Graduate Research <br>Academia Sinica<br>May '16 - June '17</p>
        </div> -->


        <div class="col-lg-2">
          <img class="rounded" src="assets/img/school/TUM.png" alt="" align="" height="150" width="150" />
          <p>Erasmus Program <br>TU München<br>Sep '14 - Mar '15</p>

        </div>


        <div class="col-lg-2">
          <img class="rounded" src="assets/img/school/nctu.png" alt="" align="" height="150" width="150" />
          <p>B.S. in ECE<br>NCTU<br>Sep '11 - June '15</p>

        </div>
      </div>

    </div><!-- /container -->
  </div><!-- /white -->



  <!-- +++++ Footer Section +++++ -->

  <div id="footer">
    <div class="container">
      <div class="row centered">

        <div class="col-lg-2 col-lg-offset-5">

          <script type="text/javascript" id="clustrmaps"
            src="//cdn.clustrmaps.com/map_v2.js?d=AlykiyJERn5mzH15z97rDSgBmOvbzSPpU2Gq2OB2-tw&cl=ffffff&w=a"></script>


        </div>
      </div>

    </div>
  </div>




  <!-- Bootstrap core JavaScript
    ================================================== -->
  <!-- Placed at the end of the document so the pages load faster -->
  <script src="assets/js/bootstrap.min.js"></script>


</body>

</html>